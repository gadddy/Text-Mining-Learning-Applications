{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.util import ngrams\n",
    "import pandas as pd\n",
    "import gensim\n",
    "import contractions\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('unique_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_stars</th>\n",
       "      <th>review_date</th>\n",
       "      <th>review_text</th>\n",
       "      <th>review_useful</th>\n",
       "      <th>review_funny</th>\n",
       "      <th>review_cool</th>\n",
       "      <th>user_name</th>\n",
       "      <th>user_review_count</th>\n",
       "      <th>user_yelping_since</th>\n",
       "      <th>user_useful</th>\n",
       "      <th>...</th>\n",
       "      <th>user_compliment_photos</th>\n",
       "      <th>tip_text</th>\n",
       "      <th>tip_date</th>\n",
       "      <th>tip_compliment_count</th>\n",
       "      <th>business_name</th>\n",
       "      <th>business_state</th>\n",
       "      <th>business_stars</th>\n",
       "      <th>business_review_count</th>\n",
       "      <th>business_categories</th>\n",
       "      <th>business_type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.0</td>\n",
       "      <td>2014-09-10 23:19:21</td>\n",
       "      <td>Yet again.. Disappointed. Now they don't have ...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Alison</td>\n",
       "      <td>146</td>\n",
       "      <td>2011-12-05 22:07:12</td>\n",
       "      <td>220</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>Yum!!! Thanks for an amazing experience</td>\n",
       "      <td>2013-10-04 22:52:17</td>\n",
       "      <td>0</td>\n",
       "      <td>Keswick Tavern</td>\n",
       "      <td>PA</td>\n",
       "      <td>3.5</td>\n",
       "      <td>159</td>\n",
       "      <td>Bars, Greek, Restaurants, Nightlife, Beer, Win...</td>\n",
       "      <td>F&amp;B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.0</td>\n",
       "      <td>2013-10-30 20:03:09</td>\n",
       "      <td>Ok really?  When I see a bar that smells like ...</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Alison</td>\n",
       "      <td>146</td>\n",
       "      <td>2011-12-05 22:07:12</td>\n",
       "      <td>220</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>Yum!!! Thanks for an amazing experience</td>\n",
       "      <td>2013-10-04 22:52:17</td>\n",
       "      <td>0</td>\n",
       "      <td>Keswick Tavern</td>\n",
       "      <td>PA</td>\n",
       "      <td>3.5</td>\n",
       "      <td>159</td>\n",
       "      <td>Bars, Greek, Restaurants, Nightlife, Beer, Win...</td>\n",
       "      <td>F&amp;B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>2013-08-08 15:11:13</td>\n",
       "      <td>The K-T is a decent place.  the bartenders are...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Alison</td>\n",
       "      <td>146</td>\n",
       "      <td>2011-12-05 22:07:12</td>\n",
       "      <td>220</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>Yum!!! Thanks for an amazing experience</td>\n",
       "      <td>2013-10-04 22:52:17</td>\n",
       "      <td>0</td>\n",
       "      <td>Keswick Tavern</td>\n",
       "      <td>PA</td>\n",
       "      <td>3.5</td>\n",
       "      <td>159</td>\n",
       "      <td>Bars, Greek, Restaurants, Nightlife, Beer, Win...</td>\n",
       "      <td>F&amp;B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.0</td>\n",
       "      <td>2014-01-25 19:21:47</td>\n",
       "      <td>Food four stars!!!!! Bartender shorting me 10 ...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Alison</td>\n",
       "      <td>146</td>\n",
       "      <td>2011-12-05 22:07:12</td>\n",
       "      <td>220</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>Yum!!! Thanks for an amazing experience</td>\n",
       "      <td>2013-10-04 22:52:17</td>\n",
       "      <td>0</td>\n",
       "      <td>Keswick Tavern</td>\n",
       "      <td>PA</td>\n",
       "      <td>3.5</td>\n",
       "      <td>159</td>\n",
       "      <td>Bars, Greek, Restaurants, Nightlife, Beer, Win...</td>\n",
       "      <td>F&amp;B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.0</td>\n",
       "      <td>2014-01-28 17:12:32</td>\n",
       "      <td>OK they get the star back for service.  Even a...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Alison</td>\n",
       "      <td>146</td>\n",
       "      <td>2011-12-05 22:07:12</td>\n",
       "      <td>220</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>Yum!!! Thanks for an amazing experience</td>\n",
       "      <td>2013-10-04 22:52:17</td>\n",
       "      <td>0</td>\n",
       "      <td>Keswick Tavern</td>\n",
       "      <td>PA</td>\n",
       "      <td>3.5</td>\n",
       "      <td>159</td>\n",
       "      <td>Bars, Greek, Restaurants, Nightlife, Beer, Win...</td>\n",
       "      <td>F&amp;B</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 35 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   review_stars          review_date  \\\n",
       "0           3.0  2014-09-10 23:19:21   \n",
       "1           4.0  2013-10-30 20:03:09   \n",
       "2           3.0  2013-08-08 15:11:13   \n",
       "3           3.0  2014-01-25 19:21:47   \n",
       "4           4.0  2014-01-28 17:12:32   \n",
       "\n",
       "                                         review_text  review_useful  \\\n",
       "0  Yet again.. Disappointed. Now they don't have ...              0   \n",
       "1  Ok really?  When I see a bar that smells like ...              5   \n",
       "2  The K-T is a decent place.  the bartenders are...              1   \n",
       "3  Food four stars!!!!! Bartender shorting me 10 ...              0   \n",
       "4  OK they get the star back for service.  Even a...              1   \n",
       "\n",
       "   review_funny  review_cool user_name  user_review_count  \\\n",
       "0             1            1    Alison                146   \n",
       "1             0            1    Alison                146   \n",
       "2             1            1    Alison                146   \n",
       "3             1            0    Alison                146   \n",
       "4             1            1    Alison                146   \n",
       "\n",
       "    user_yelping_since  user_useful  ...  user_compliment_photos  \\\n",
       "0  2011-12-05 22:07:12          220  ...                       0   \n",
       "1  2011-12-05 22:07:12          220  ...                       0   \n",
       "2  2011-12-05 22:07:12          220  ...                       0   \n",
       "3  2011-12-05 22:07:12          220  ...                       0   \n",
       "4  2011-12-05 22:07:12          220  ...                       0   \n",
       "\n",
       "                                  tip_text             tip_date  \\\n",
       "0  Yum!!! Thanks for an amazing experience  2013-10-04 22:52:17   \n",
       "1  Yum!!! Thanks for an amazing experience  2013-10-04 22:52:17   \n",
       "2  Yum!!! Thanks for an amazing experience  2013-10-04 22:52:17   \n",
       "3  Yum!!! Thanks for an amazing experience  2013-10-04 22:52:17   \n",
       "4  Yum!!! Thanks for an amazing experience  2013-10-04 22:52:17   \n",
       "\n",
       "  tip_compliment_count   business_name  business_state  business_stars  \\\n",
       "0                    0  Keswick Tavern              PA             3.5   \n",
       "1                    0  Keswick Tavern              PA             3.5   \n",
       "2                    0  Keswick Tavern              PA             3.5   \n",
       "3                    0  Keswick Tavern              PA             3.5   \n",
       "4                    0  Keswick Tavern              PA             3.5   \n",
       "\n",
       "   business_review_count                                business_categories  \\\n",
       "0                    159  Bars, Greek, Restaurants, Nightlife, Beer, Win...   \n",
       "1                    159  Bars, Greek, Restaurants, Nightlife, Beer, Win...   \n",
       "2                    159  Bars, Greek, Restaurants, Nightlife, Beer, Win...   \n",
       "3                    159  Bars, Greek, Restaurants, Nightlife, Beer, Win...   \n",
       "4                    159  Bars, Greek, Restaurants, Nightlife, Beer, Win...   \n",
       "\n",
       "   business_type  \n",
       "0            F&B  \n",
       "1            F&B  \n",
       "2            F&B  \n",
       "3            F&B  \n",
       "4            F&B  \n",
       "\n",
       "[5 rows x 35 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review_stars</th>\n",
       "      <th>review_useful</th>\n",
       "      <th>review_funny</th>\n",
       "      <th>review_cool</th>\n",
       "      <th>user_review_count</th>\n",
       "      <th>user_useful</th>\n",
       "      <th>user_funny</th>\n",
       "      <th>user_cool</th>\n",
       "      <th>user_fans</th>\n",
       "      <th>user_average_stars</th>\n",
       "      <th>...</th>\n",
       "      <th>user_compliment_list</th>\n",
       "      <th>user_compliment_note</th>\n",
       "      <th>user_compliment_plain</th>\n",
       "      <th>user_compliment_cool</th>\n",
       "      <th>user_compliment_funny</th>\n",
       "      <th>user_compliment_writer</th>\n",
       "      <th>user_compliment_photos</th>\n",
       "      <th>tip_compliment_count</th>\n",
       "      <th>business_stars</th>\n",
       "      <th>business_review_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>102326.000000</td>\n",
       "      <td>102326.000000</td>\n",
       "      <td>102326.000000</td>\n",
       "      <td>102326.000000</td>\n",
       "      <td>102326.000000</td>\n",
       "      <td>102326.000000</td>\n",
       "      <td>102326.000000</td>\n",
       "      <td>102326.000000</td>\n",
       "      <td>102326.000000</td>\n",
       "      <td>102326.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>102326.000000</td>\n",
       "      <td>102326.000000</td>\n",
       "      <td>102326.000000</td>\n",
       "      <td>102326.000000</td>\n",
       "      <td>102326.000000</td>\n",
       "      <td>102326.000000</td>\n",
       "      <td>102326.000000</td>\n",
       "      <td>102326.000000</td>\n",
       "      <td>102326.000000</td>\n",
       "      <td>102326.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>4.064402</td>\n",
       "      <td>3.220423</td>\n",
       "      <td>1.207718</td>\n",
       "      <td>2.108604</td>\n",
       "      <td>482.571321</td>\n",
       "      <td>2979.490364</td>\n",
       "      <td>1319.419522</td>\n",
       "      <td>2210.992065</td>\n",
       "      <td>94.561930</td>\n",
       "      <td>3.947441</td>\n",
       "      <td>...</td>\n",
       "      <td>3.891113</td>\n",
       "      <td>136.283711</td>\n",
       "      <td>399.515861</td>\n",
       "      <td>263.000303</td>\n",
       "      <td>263.000303</td>\n",
       "      <td>85.245509</td>\n",
       "      <td>128.731808</td>\n",
       "      <td>0.023015</td>\n",
       "      <td>3.792057</td>\n",
       "      <td>391.609454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.013901</td>\n",
       "      <td>6.224662</td>\n",
       "      <td>3.455563</td>\n",
       "      <td>5.449386</td>\n",
       "      <td>631.814355</td>\n",
       "      <td>8296.960979</td>\n",
       "      <td>4819.579650</td>\n",
       "      <td>6965.832324</td>\n",
       "      <td>304.943573</td>\n",
       "      <td>0.326913</td>\n",
       "      <td>...</td>\n",
       "      <td>26.467907</td>\n",
       "      <td>486.853147</td>\n",
       "      <td>1464.561770</td>\n",
       "      <td>896.127814</td>\n",
       "      <td>896.127814</td>\n",
       "      <td>263.318674</td>\n",
       "      <td>689.151990</td>\n",
       "      <td>0.166504</td>\n",
       "      <td>0.619643</td>\n",
       "      <td>697.951534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.440000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>140.000000</td>\n",
       "      <td>225.000000</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>96.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>3.730000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.500000</td>\n",
       "      <td>67.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>273.000000</td>\n",
       "      <td>562.000000</td>\n",
       "      <td>151.000000</td>\n",
       "      <td>271.000000</td>\n",
       "      <td>24.000000</td>\n",
       "      <td>3.960000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>26.000000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>179.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>552.000000</td>\n",
       "      <td>1767.000000</td>\n",
       "      <td>592.000000</td>\n",
       "      <td>1009.000000</td>\n",
       "      <td>65.000000</td>\n",
       "      <td>4.170000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>66.000000</td>\n",
       "      <td>118.000000</td>\n",
       "      <td>122.000000</td>\n",
       "      <td>122.000000</td>\n",
       "      <td>54.000000</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>418.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>360.000000</td>\n",
       "      <td>141.000000</td>\n",
       "      <td>360.000000</td>\n",
       "      <td>17473.000000</td>\n",
       "      <td>206296.000000</td>\n",
       "      <td>185823.000000</td>\n",
       "      <td>195814.000000</td>\n",
       "      <td>12497.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>2413.000000</td>\n",
       "      <td>59031.000000</td>\n",
       "      <td>101097.000000</td>\n",
       "      <td>49967.000000</td>\n",
       "      <td>49967.000000</td>\n",
       "      <td>15934.000000</td>\n",
       "      <td>56104.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>7568.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        review_stars  review_useful   review_funny    review_cool  \\\n",
       "count  102326.000000  102326.000000  102326.000000  102326.000000   \n",
       "mean        4.064402       3.220423       1.207718       2.108604   \n",
       "std         1.013901       6.224662       3.455563       5.449386   \n",
       "min         1.000000       0.000000       0.000000       0.000000   \n",
       "25%         4.000000       0.000000       0.000000       0.000000   \n",
       "50%         4.000000       2.000000       0.000000       1.000000   \n",
       "75%         5.000000       4.000000       1.000000       2.000000   \n",
       "max         5.000000     360.000000     141.000000     360.000000   \n",
       "\n",
       "       user_review_count    user_useful     user_funny      user_cool  \\\n",
       "count      102326.000000  102326.000000  102326.000000  102326.000000   \n",
       "mean          482.571321    2979.490364    1319.419522    2210.992065   \n",
       "std           631.814355    8296.960979    4819.579650    6965.832324   \n",
       "min            12.000000       1.000000       0.000000       0.000000   \n",
       "25%           140.000000     225.000000      50.000000      96.000000   \n",
       "50%           273.000000     562.000000     151.000000     271.000000   \n",
       "75%           552.000000    1767.000000     592.000000    1009.000000   \n",
       "max         17473.000000  206296.000000  185823.000000  195814.000000   \n",
       "\n",
       "           user_fans  user_average_stars  ...  user_compliment_list  \\\n",
       "count  102326.000000       102326.000000  ...         102326.000000   \n",
       "mean       94.561930            3.947441  ...              3.891113   \n",
       "std       304.943573            0.326913  ...             26.467907   \n",
       "min         0.000000            2.440000  ...              0.000000   \n",
       "25%        10.000000            3.730000  ...              0.000000   \n",
       "50%        24.000000            3.960000  ...              0.000000   \n",
       "75%        65.000000            4.170000  ...              1.000000   \n",
       "max     12497.000000            5.000000  ...           2413.000000   \n",
       "\n",
       "       user_compliment_note  user_compliment_plain  user_compliment_cool  \\\n",
       "count         102326.000000          102326.000000         102326.000000   \n",
       "mean             136.283711             399.515861            263.000303   \n",
       "std              486.853147            1464.561770            896.127814   \n",
       "min                0.000000               0.000000              0.000000   \n",
       "25%                8.000000               9.000000             10.000000   \n",
       "50%               20.000000              26.000000             31.000000   \n",
       "75%               66.000000             118.000000            122.000000   \n",
       "max            59031.000000          101097.000000          49967.000000   \n",
       "\n",
       "       user_compliment_funny  user_compliment_writer  user_compliment_photos  \\\n",
       "count          102326.000000           102326.000000           102326.000000   \n",
       "mean              263.000303               85.245509              128.731808   \n",
       "std               896.127814              263.318674              689.151990   \n",
       "min                 0.000000                0.000000                0.000000   \n",
       "25%                10.000000                6.000000                2.000000   \n",
       "50%                31.000000               17.000000                7.000000   \n",
       "75%               122.000000               54.000000               39.000000   \n",
       "max             49967.000000            15934.000000            56104.000000   \n",
       "\n",
       "       tip_compliment_count  business_stars  business_review_count  \n",
       "count         102326.000000   102326.000000          102326.000000  \n",
       "mean               0.023015        3.792057             391.609454  \n",
       "std                0.166504        0.619643             697.951534  \n",
       "min                0.000000        1.000000               5.000000  \n",
       "25%                0.000000        3.500000              67.000000  \n",
       "50%                0.000000        4.000000             179.000000  \n",
       "75%                0.000000        4.000000             418.000000  \n",
       "max                5.000000        5.000000            7568.000000  \n",
       "\n",
       "[8 rows x 24 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label the data with new column where review_stars is greater than 3 is positive and less than 3 is negative and equal to 3 is neutral\n",
    "df['sentiment'] = df['review_stars'].apply(lambda x: 'positive' if x > 3 else 'negative' if x < 3 else 'neutral')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished reading sentences.\n"
     ]
    }
   ],
   "source": [
    "# Preprocess the data\n",
    "stop_list = nltk.corpus.stopwords.words('english')\n",
    "lemmatizer = nltk.stem.WordNetLemmatizer()\n",
    "\n",
    "# We use the following list to store the sequence of sentence labels.\n",
    "labels = []\n",
    "\n",
    "# We use the following list to store the sentences, where each sentence itself is a list of words.\n",
    "corpus = []\n",
    "\n",
    "# For every row in the data frame\n",
    "for index, row in df.iterrows():\n",
    "    # Extract the label and the text.\n",
    "    label = row['sentiment']\n",
    "    text = row['review_text']\n",
    "    \n",
    "    # Store the label into the list of labels.\n",
    "    labels.append(label)\n",
    "    \n",
    "    # Tokenize the text.\n",
    "    sent = nltk.word_tokenize(text)\n",
    "    \n",
    "    # Lowercase conversion\n",
    "    sent = [w.lower() for w in sent]\n",
    "    \n",
    "    # Stop word removal \n",
    "    sent = [w for w in sent if w not in stop_list]\n",
    "\n",
    "    # Remove punctuation\n",
    "    sent = [w for w in sent if w.isalnum()]\n",
    "    \n",
    "    # Lemmatization \n",
    "    sent = [lemmatizer.lemmatize(w) for w in sent]\n",
    "\n",
    "    # Expand contractions\n",
    "    sent = [contractions.fix(w) for w in sent]\n",
    "\n",
    "    # Create bigrams\n",
    "    bigrams = [' '.join(w) for w in list(ngrams(sent, 2))]\n",
    "    sent.extend(bigrams)\n",
    "    \n",
    "    \n",
    "    # Store the sentence into the corpus.\n",
    "    corpus.append(sent)\n",
    "\n",
    "print('Finished reading sentences.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished preparing the data.\n"
     ]
    }
   ],
   "source": [
    "# Create a dictionary from the corpus.\n",
    "dictionary = gensim.corpora.Dictionary(corpus)\n",
    "\n",
    "# Store the labeled training data in the following list.\n",
    "labeled_data = []\n",
    "count = 0\n",
    "# Going through the two lists in parallel to create the labeled data set.\n",
    "for (l, s) in zip(labels, corpus):\n",
    "\n",
    "    # Convert the original sentence into a vector.\n",
    "    vector = dictionary.doc2bow(s)\n",
    "    \n",
    "    # Create a dict object to store the document vector (in order to use NLTK's classifier later)\n",
    "    sent_as_dict = {id:1 for (id, tf) in vector}\n",
    "    \n",
    "    # Add the labeled sentence to the labeled data set.\n",
    "    labeled_data.append((sent_as_dict, l))\n",
    "    \n",
    "print('Finished preparing the data.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('dictionary.pickle', 'wb') as handle:\n",
    "    pickle.dump(dictionary, handle)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished splitting the data.\n"
     ]
    }
   ],
   "source": [
    "# Split the data into training, validation, and test sets using 60%, 20%, 20% respectively.\n",
    "train_size = int(len(labeled_data) * 0.6)\n",
    "val_size = int(len(labeled_data) * 0.2)\n",
    "train_data = labeled_data[:train_size]\n",
    "val_data = labeled_data[train_size:train_size+val_size]\n",
    "test_data = labeled_data[train_size+val_size:]\n",
    "\n",
    "print('Finished splitting the data.')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  ==> Training (10 iterations)\n",
      "\n",
      "      Iteration    Log Likelihood    Accuracy\n",
      "      ---------------------------------------\n",
      "             1          -1.09861        0.791\n",
      "             2          -1.09855        0.791\n",
      "             3          -1.09848        0.791\n",
      "             4          -1.09841        0.791\n",
      "             5          -1.09835        0.791\n",
      "             6          -1.09828        0.791\n",
      "             7          -1.09822        0.791\n",
      "             8          -1.09815        0.791\n",
      "             9          -1.09808        0.791\n",
      "         Final          -1.09802        0.791\n"
     ]
    }
   ],
   "source": [
    "numIterations = 10\n",
    "algorithm = nltk.classify.MaxentClassifier.ALGORITHMS[0]\n",
    "entclassifier = nltk.MaxentClassifier.train(train_data, algorithm, max_iter=numIterations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score: 0.8562327102020285\n",
      "Validation accuracy: 0.7486074464966286\n"
     ]
    }
   ],
   "source": [
    "# Evaluate base on accuracy and f1_score\n",
    "import collections\n",
    "from nltk.metrics import f_measure\n",
    "\n",
    "# Compute f1 scores for each label.\n",
    "refsets = collections.defaultdict(set)\n",
    "testsets = collections.defaultdict(set)\n",
    "for i, (feats, label) in enumerate(test_data):\n",
    "    refsets[label].add(i)\n",
    "    observed = entclassifier.classify(feats)\n",
    "    testsets[observed].add(i)\n",
    "\n",
    "accuracy = nltk.classify.accuracy(entclassifier, test_data)\n",
    "print( 'F1 score:', f_measure(refsets['positive'], testsets['positive']) )\n",
    "print('Validation accuracy:', accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "import pickle\n",
    "\n",
    "with open('sentiment_classifier.pkl', 'wb') as f:\n",
    "    pickle.dump(entclassifier, f)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict the sentiment of a new review\n",
    "def predict_sentiment(text):\n",
    "    sent = nltk.word_tokenize(text)\n",
    "    \n",
    "    # Lowercase conversion\n",
    "    sent = [w.lower() for w in sent]\n",
    "    \n",
    "    # Stop word removal \n",
    "    sent = [w for w in sent if w not in stop_list]\n",
    "\n",
    "    # Remove punctuation\n",
    "    sent = [w for w in sent if w.isalnum()]\n",
    "    \n",
    "    # Lemmatization \n",
    "    sent = [lemmatizer.lemmatize(w) for w in sent]\n",
    "\n",
    "    # Expand contractions\n",
    "    sent = [contractions.fix(w) for w in sent]\n",
    "\n",
    "    # Create bigrams\n",
    "    bigrams = [' '.join(w) for w in list(ngrams(sent, 2))]\n",
    "    \n",
    "    sent.extend(bigrams)\n",
    "    \n",
    "    # Convert the original sentence into a vector.\n",
    "    vector = dictionary.doc2bow(sent)\n",
    "    \n",
    "    # Create a dict object to store the document vector (in order to use NLTK's classifier later)\n",
    "    sent_as_dict = {id:1 for (id, tf) in vector}\n",
    "    \n",
    "    # Predict the sentiment of the review.\n",
    "    return entclassifier.classify(sent_as_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "positive\n"
     ]
    }
   ],
   "source": [
    "# Predict text\n",
    "text = \"BEST experience I have ever had at the KT on 6/14/2015.  John, our server, was amazing.  Really awesome.  The food was awesome as well.  I was sooooo happy we went.  Great job guys!!  Keep up the great work.  BTW the burgers are amazing.  Thanks again!\"\n",
    "print(predict_sentiment(text))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
